####ä¸­é—´çš„æ•°æ®å€Ÿå£è·å–æˆåˆ†è‚¡å†å²å¸‚å€¼æ˜¯å¯è¡Œçš„ï¼Œä½†æ˜¯ä¼šè¢«æ¥å£æ‹’ç»
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from collections import Counter
import akshare as ak

FILE_PATH = r"C:\Users\cufet\Desktop\å›¾ç‰‡\ä¸­è¯500æˆåˆ†è‚¡æ•°æ®-å¿«ç…§1.xlsx"
WINDOW = 365
ANNUALIZATION_FACTOR = 365

# ä½ æƒ³è®¡ç®—çš„ç‰¹å®šæ—¥æœŸåˆ—è¡¨
# æ³¨æ„ï¼šå¦‚æœ 1/1 æˆ– 7/1 æ˜¯éäº¤æ˜“æ—¥ï¼Œæˆ‘ä»¬ä¼šå°è¯•åŒ¹é…åˆ°è¯¥æ—¥æœŸè®¡ç®—å‡ºçš„åæ–¹å·®ç»“æœ
TARGET_DATES = [
    datetime(2023, 1, 1),
    datetime(2023, 7, 1),
    datetime(2024, 1, 1),
    datetime(2024, 7, 1),
    datetime(2025, 1, 1),
    datetime(2025, 7, 1),
]

# --- 1. æ•°æ®è¯»å–ä¸é¢„å¤„ç† ---
# --- 1. æ•°æ®è¯»å–ä¸é¢„å¤„ç† (ä¿®æ­£é¡ºåº) ---

try:
    df_sheet1 = pd.read_excel(FILE_PATH, sheet_name='Sheet1', header=0)
    df_sheet2 = pd.read_excel(FILE_PATH, sheet_name='Sheet2', header=0)
except FileNotFoundError:
    print("é”™è¯¯ï¼šæ— æ³•æ‰¾åˆ°Excelæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
    exit()
stock_codes_raw = df_sheet1.columns[1:].tolist()
print(stock_codes_raw)
formatted_stock_codes = []
for code in stock_codes_raw:
    parts = code.split('.')
    if len(parts) == 2 and parts[0].isdigit() and len(parts[0]) == 6:
        # æå–çº¯æ•°å­—ä»£ç ï¼Œå¦‚ä» '600006.SH' æå– '600006'
        symbol = parts[0]
        formatted_stock_codes.append(symbol)
    else:
        # å¤„ç†å¯èƒ½çš„é”™è¯¯æ•°æ®
        print(f"è­¦å‘Šï¼šè·³è¿‡éæ ‡å‡†ä»£ç æ ¼å¼: {code}")
        pass

stock_codes = formatted_stock_codes
print("è½¬æ¢åçš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ (çº¯æ•°å­—æ ¼å¼):")
print(stock_codes)

# 1.1 æå–å¹¶ä¿®æ­£è‚¡ç¥¨ä»£ç  (Excelçš„ç¬¬äºŒè¡Œ)
# åŸå§‹çš„ df_sheet1.iloc[0] åŒ…å«äº†è‚¡ç¥¨ä»£ç è¡Œå’Œå·¦ä¸Šè§’çš„é‚£ä¸ªç©º/æ—¥æœŸå•å…ƒæ ¼å€¼
# æˆ‘ä»¬åªå–è‚¡ç¥¨ä»£ç éƒ¨åˆ†ï¼Œå¹¶ä» df_sheet1 ä¸­åˆ é™¤è¿™ä¸¤è¡Œæ ‡é¢˜/ä»£ç è¡Œ
stock_codes = df_sheet1.iloc[0].tolist()[1:] # ***ä¿®æ­£ç‚¹ï¼š[1:] æ’é™¤ç¬¬ä¸€åˆ—çš„æ—¥æœŸæ ‡é¢˜***
df_sheet1 = df_sheet1.iloc[1:].copy() # åˆ é™¤ä½œä¸ºä»£ç çš„ç¬¬äºŒè¡Œ (åŸExcelçš„ç¬¬äºŒè¡Œ)
# df_sheet1 ç°åœ¨åªå‰©ä¸‹æ•°æ®ï¼Œåˆ—åä»ç„¶æ˜¯ Excel çš„ç¬¬ä¸€è¡Œæ ‡é¢˜ ('æ—¥æœŸ', 'è‚¡ç¥¨1', 'è‚¡ç¥¨2', ...)

# 1.2 è®¾ç½®æ—¥æœŸç´¢å¼•
df_sheet1.iloc[:, 0] = pd.to_datetime(df_sheet1.iloc[:, 0])
# è¿™ä¸€æ­¥å°†ç¬¬ä¸€åˆ—æ—¥æœŸè®¾ç½®ä¸ºç´¢å¼•ï¼ŒDataFrame è‡ªåŠ¨åªå‰©ä¸‹è‚¡ç¥¨ä»·æ ¼åˆ—
df_sheet1.set_index(df_sheet1.columns[0], inplace=True)

# 1.3 å¤„ç†é‡å¤åˆ—åå¹¶è®¾ç½®åˆ—åï¼ˆè§£å†³ InvalidIndexErrorï¼‰
duplicates = [item for item, count in Counter(stock_codes).items() if count > 1]
if duplicates:
    # è‡ªåŠ¨ä¸ºé‡å¤åˆ—ååŠ åç¼€
    df_sheet1.columns = pd.Index(stock_codes).make_unique()
else:
    # ***ä¿®æ­£ç‚¹ï¼šç°åœ¨ stock_codes çš„é•¿åº¦å’Œ df_sheet1 çš„åˆ—æ•°åº”è¯¥åŒ¹é…äº†***
    df_sheet1.columns = stock_codes

# 1.4 è½¬æ¢ä¸ºæ•°å€¼å‹å¹¶æ¸…ç†
df_sheet1 = df_sheet1.apply(pd.to_numeric, errors='coerce')
df_sheet1.dropna(how='all', inplace=True)
df_sheet1.dropna(axis=1, how='all', inplace=True)

print(f"æ•°æ®å¤„ç†å®Œæˆã€‚è‚¡ç¥¨æ•°é‡: {len(df_sheet1.columns)}")

# --- 2. åæ–¹å·®çŸ©é˜µè®¡ç®—å‡½æ•° ---
# --- 2. åæ–¹å·®çŸ©é˜µè®¡ç®—å‡½æ•° (æ‰‹åŠ¨è®¡ç®—ç›®æ ‡çª—å£) ---
def calculate_target_covariances(df, target_dates, window, annualization_factor):
    """
    è®¡ç®—ç‰¹å®šæ—¥æœŸçš„æ»šåŠ¨åæ–¹å·®çŸ©é˜µï¼Œé€šè¿‡æ‰‹åŠ¨åˆ‡ç‰‡é¿å…è®¡ç®—æ‰€æœ‰æ—¥æœŸçš„åæ–¹å·®ã€‚
    """
    results = {}

    print("\næ­¥éª¤ 1/3: è®¡ç®—æ¯æ—¥å¯¹æ•°æ”¶ç›Šç‡ (å…¨æ•°æ®é›†)...")
    # å¯¹æ•°æ”¶ç›Šç‡ä»éœ€åœ¨å…¨æ•°æ®é›†ä¸Šè®¡ç®—ä¸€æ¬¡
    log_returns = np.log(df / df.shift(1))

    # æ‰¾åˆ° log_returns ä¸­æ‰€æœ‰å¯ä»¥è®¡ç®—çš„æ—¥æœŸï¼ˆè·³è¿‡ç¬¬ä¸€ä¸ª NaNï¼‰
    available_dates = log_returns.index[log_returns.notna().all(axis=1)]

    print("æ­¥éª¤ 2/3: éå†ç›®æ ‡æ—¥æœŸå¹¶æ‰‹åŠ¨è®¡ç®—çª—å£åæ–¹å·®...")

    # éå†ç›®æ ‡æ—¥æœŸ
    for target_date in target_dates:

        # 1. ç¡®å®šå®é™…è®¡ç®—æ—¥æœŸ (å¤„ç†éäº¤æ˜“æ—¥)
        if target_date not in df.index:
            # æ‰¾åˆ°ç›®æ ‡æ—¥æœŸæˆ–å…¶ä¹‹åçš„ç¬¬ä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºå®é™…è®¡ç®—æ—¥
            if available_dates.empty or target_date > available_dates.max():
                print(f"  è­¦å‘Šï¼šç›®æ ‡ {target_date.date()} ä¹‹åæ²¡æœ‰å¯ç”¨æ•°æ®ã€‚è·³è¿‡ã€‚")
                continue

            # æ‰¾åˆ°ç›®æ ‡æ—¥æœŸæˆ–å…¶ä¹‹åçš„ç¬¬ä¸€ä¸ª**æœ‰æ•°æ®**çš„æ—¥æœŸ
            calculated_date = available_dates[available_dates >= target_date].min()
            if pd.isna(calculated_date):
                print(f"  è­¦å‘Šï¼šç›®æ ‡ {target_date.date()} ä¹‹åæ²¡æœ‰å¯ç”¨æ•°æ®ã€‚è·³è¿‡ã€‚")
                continue

            print(f"  ç›®æ ‡ {target_date.date()} (éäº¤æ˜“æ—¥)ã€‚ä½¿ç”¨ {calculated_date.date()} è¿›è¡Œè®¡ç®—ã€‚")
        else:
            calculated_date = target_date
            print(f"  æ­£åœ¨è®¡ç®— {calculated_date.date()} çš„åæ–¹å·®...")

        # 2. ç¡®å®šçª—å£èµ·å§‹æ—¥æœŸ
        try:
            current_idx = df.index.get_loc(calculated_date)
            # æ‰¾åˆ°çª—å£çš„èµ·å§‹æ—¥æœŸ
            start_date = df.index[current_idx - window + 1]
        except (IndexError, KeyError) as e:
            print(f"  è­¦å‘Šï¼š{calculated_date.date()} å¤ªæ—©ï¼Œæ— æ³•è®¡ç®—å®Œæ•´çš„ {window} å¤©çª—å£ã€‚è·³è¿‡ã€‚")
            continue

        # 3. æ ¸å¿ƒè®¡ç®—ï¼šåˆ‡ç‰‡å¹¶è®¡ç®— cov()
        # ä»…åˆ‡å‡ºç›®æ ‡çª—å£å†…çš„å¯¹æ•°æ”¶ç›Šç‡æ•°æ®
        window_log_returns = log_returns.loc[start_date:calculated_date]

        # è®¡ç®—è¯¥çª—å£çš„æ—¥åæ–¹å·®çŸ©é˜µ
        current_cov_daily = window_log_returns.cov()
        # å¼ºåˆ¶è½¬æ¢ä¸ºç»Ÿä¸€çš„æ•°å€¼ç±»å‹
        print("  æ­£åœ¨è½¬æ¢æ•°æ®ç±»å‹...")
        current_cov_numeric = current_cov_daily.apply(pd.to_numeric, errors='coerce')
        # æ£€æŸ¥è½¬æ¢åçš„NaNå€¼
        nan_count = current_cov_numeric.isna().sum().sum()
        if nan_count > 0:
            print(f"  è­¦å‘Š: è½¬æ¢åæœ‰ {nan_count} ä¸ªNaNå€¼ï¼Œä½¿ç”¨0å¡«å……")
            current_cov_numeric = current_cov_numeric.fillna(1e-5)

        print(f"  è½¬æ¢åæ•°æ®ç±»å‹: {current_cov_numeric.dtypes.iloc[0]}")
        current_cov = current_cov_numeric * annualization_factor

        # 4. è®¡ç®—æ»šåŠ¨å‡å€¼ (å§‹æœ«ä»·æ ¼æ”¶ç›Šç‡)
        annual_return = (df.loc[calculated_date] / df.loc[start_date]) - 1

        # 5. å­˜å‚¨ç»“æœ
        result_entry = {
            'rolling_mean': annual_return,
            'rolling_cov': current_cov,
        }
        if target_date != calculated_date:
            result_entry['calculated_on'] = calculated_date

        results[target_date] = result_entry
        print(f"  âˆš è®¡ç®—å®Œæˆï¼Œåæ–¹å·®çŸ©é˜µç»´åº¦: {current_cov.shape[0]} x {current_cov.shape[1]}")
        print(f"  === åæ–¹å·®çŸ©é˜µè°ƒè¯•ä¿¡æ¯ ===")
        print(f"  current_cov ç±»å‹: {type(current_cov)}")
        print(f"  current_cov å½¢çŠ¶: {getattr(current_cov, 'shape', 'No shape')}")
        print(f"  current_cov æ•°æ®ç±»å‹: {getattr(current_cov, 'dtype', 'No dtype')}")

    return results


# --- 3. æ‰§è¡Œè®¡ç®—ä¸è¾“å‡º ---
# (å‰©ä½™çš„ä»£ç ä¿æŒä¸å˜ï¼Œå› ä¸ºå‡½æ•°æ¥å£æ²¡æœ‰å˜)

print("\n--- å¼€å§‹è®¡ç®—æŒ‡å®šæ—¥æœŸçš„åæ–¹å·®çŸ©é˜µ (æ‰‹åŠ¨åˆ‡ç‰‡æ¨¡å¼) ---")

# æ‰§è¡Œè®¡ç®—
rolling_stats = calculate_target_covariances(
    df_sheet1, TARGET_DATES, WINDOW, ANNUALIZATION_FACTOR
)

# --- 4. ç»“æœå±•ç¤º ---
print("\n" + "=" * 40)
print("åæ–¹å·®é˜µè®¡ç®—å®Œæˆ")
print("=" * 40)

for date, data in rolling_stats.items():
    calculated_date = data.get('calculated_on', date)
    print(
        f"\nç›®æ ‡æ—¥æœŸ: {date.date()}" + (f" (å®é™…è®¡ç®—æ—¥: {calculated_date.date()})" if date != calculated_date else ""))

    # åæ–¹å·®çŸ©é˜µç»´åº¦
    cov_shape = data['rolling_cov'].shape
    print(f"  åæ–¹å·®çŸ©é˜µç»´åº¦: {cov_shape[0]} x {cov_shape[1]}")

    # å‡å€¼é¢„è§ˆ (ä»…æ˜¾ç¤ºå‰ 5 ä¸ª)
    print("  æ»šåŠ¨å¹´åŒ–å‡å€¼ (å‰5æ”¯è‚¡ç¥¨):")
    print(data['rolling_mean'].head().to_string())

# --- ç¬¬äºŒæ­¥: æå– Sheet2 ä¸­çš„é£é™©æº¢ä»· ---

# å‡è®¾ H åˆ—ä¸ºæ—¥æœŸï¼ˆç´¢å¼• 7ï¼‰ï¼ŒI åˆ—ä¸ºé£é™©æº¢ä»·ï¼ˆç´¢å¼• 8ï¼‰
RP_DATE_COL_INDEX = 3
RP_VALUE_COL_INDEX = 6

print("\n--- ç¬¬äºŒæ­¥: æå– Sheet2 é£é™©æº¢ä»· ---")

# 1. æå– H åˆ—æ—¥æœŸå’Œ I åˆ—é£é™©æº¢ä»·å€¼
rp_dates = df_sheet2.iloc[:, RP_DATE_COL_INDEX]
rp_values = df_sheet2.iloc[:, RP_VALUE_COL_INDEX]

# 2. æ¸…ç†æ•°æ®å¹¶åˆ›å»ºé£é™©æº¢ä»· Series
try:
    # å°è¯•å°†æ—¥æœŸåˆ—è½¬æ¢ä¸º datetime å¯¹è±¡
    rp_dates = pd.to_datetime(rp_dates, errors='coerce')
    # å°è¯•å°†é£é™©æº¢ä»·åˆ—è½¬æ¢ä¸ºæ•°å€¼å‹
    rp_values = pd.to_numeric(rp_values, errors='coerce')
except Exception as e:
    print(f"æ•°æ®è½¬æ¢å¤±è´¥ï¼š{e}")
    exit()

# 3. ç§»é™¤ä»»ä½•åŒ…å« NaN çš„è¡Œå¹¶åˆ›å»º Series
valid_mask = rp_dates.notna() & rp_values.notna()
risk_premium_series = pd.Series(rp_values[valid_mask].values, index=rp_dates[valid_mask])
risk_premium_series = risk_premium_series.sort_index()

print(f"Sheet2 é£é™©æº¢ä»·æ•°æ®æ—¶é—´èŒƒå›´: {risk_premium_series.index.min().date()} åˆ° {risk_premium_series.index.max().date()}")

# 4. é’ˆå¯¹ TARGET_DATES è¿›è¡Œæå–ï¼ˆä½¿ç”¨ ffill ç¡®ä¿æ‰¾åˆ°æœ€è¿‘çš„æ•°æ®ï¼‰
# æå– TARGET_DATES åˆ—è¡¨ä¸­çš„æ—¥æœŸ
target_rp_data = risk_premium_series.reindex(TARGET_DATES, method='ffill')

# --- ç»“æœå±•ç¤º ---
print("\n" + "=" * 40)
print("ç›®æ ‡æ—¥æœŸå¯¹åº”çš„é£é™©æº¢ä»·:")
print("=" * 40)
print(target_rp_data.to_string())

###ç¬¬ä¸‰æ­¥ï¼Œè®¡ç®—6ä¸ªæ—¶é—´ç‚¹çš„å…ˆéªŒåˆ†å¸ƒ
###è¿™ç§é¢‘ç¹ä¸”æš´åŠ›çš„å¤„ç†æ–¹å¼ä¼šè¢«akshareå¼ºåˆ¶ä¸­æ–­
# def get_market_values_for_dates(codes, dates):
#     """
#     é€šè¿‡å¾ªç¯è·å–æ¯åªè‚¡ç¥¨åœ¨ç»™å®šæ—¥æœŸæˆ–æœ€è¿‘äº¤æ˜“æ—¥çš„æ€»å¸‚å€¼æ•°æ®ã€‚
#     ç›´æ¥æœç´¢ç»™å®šæ—¥æœŸçš„æ”¶ç›˜ä»·ï¼Œç»“åˆæ€»è‚¡æœ¬è®¡ç®—å¸‚å€¼ã€‚
#
#     Args:
#         codes (list): è‚¡ç¥¨ä»£ç åˆ—è¡¨ã€‚
#         dates (list): ç›®æ ‡æ—¥æœŸåˆ—è¡¨ (datetimeå¯¹è±¡)ã€‚
#
#     Returns:
#         pd.DataFrame: ç´¢å¼•ä¸ºæ—¥æœŸï¼Œåˆ—ä¸ºè‚¡ç¥¨ä»£ç çš„æ€»å¸‚å€¼DataFrameã€‚
#     """
#     all_market_caps = {}
#
#     print("--- æ­¥éª¤ 1: å¾ªç¯è·å–æ¯åªè‚¡ç¥¨çš„å¸‚å€¼æ•°æ® ---")
#
#     for code in codes:
#         try:
#             print(f"  æ­£åœ¨å¤„ç† {code}...")
#
#             # 1. è·å–è¯¥è‚¡ç¥¨çš„æœ€æ–°æ€»è‚¡æœ¬ä¿¡æ¯
#             df_stock_info = ak.stock_individual_info_em(symbol=code)
#             if df_stock_info.empty:
#                 print(f"    âœ— æ— æ³•è·å–è‚¡ç¥¨ä¿¡æ¯")
#                 continue
#
#             info_indexed = df_stock_info.set_index('item')
#
#             # æå–æ€»è‚¡æœ¬ï¼Œå•ä½æ˜¯"è‚¡"
#             if 'æ€»è‚¡æœ¬' in info_indexed.index:
#                 total_shares = info_indexed.loc['æ€»è‚¡æœ¬', 'value']
#                 print(f"    æ€»è‚¡æœ¬: {total_shares:.0f} è‚¡")
#             else:
#                 print(f"    âœ— æ— æ³•è·å–æ€»è‚¡æœ¬ä¿¡æ¯")
#                 continue
#
#             # 2. è·å–å†å²è¡Œæƒ…æ•°æ® - åªè·å–å¿…è¦çš„æ•°æ®èŒƒå›´
#             # ç¡®å®šæ—¥æœŸèŒƒå›´ï¼šæœ€æ—©çš„ç›®æ ‡æ—¥æœŸåˆ°æœ€æ™šçš„ç›®æ ‡æ—¥æœŸ
#             min_date = min(dates)
#             max_date = max(dates)
#
#             # æ‰©å±•ä¸€äº›æ—¥æœŸèŒƒå›´ä»¥ç¡®ä¿è¦†ç›–
#             start_date = (min_date - timedelta(days=30)).strftime('%Y%m%d')
#             end_date = (max_date + timedelta(days=30)).strftime('%Y%m%d')
#
#             df_hist = ak.stock_zh_a_hist(
#                 symbol=code,
#                 period="daily",
#                 start_date=start_date,
#                 end_date=end_date,
#                 adjust="qfq"
#             )
#
#             if df_hist.empty:
#                 print(f"    âœ— å†å²æ•°æ®è¿”å›ä¸ºç©º")
#                 continue
#
#             # 3. å¤„ç†å†å²æ•°æ®
#             df_hist['æ—¥æœŸ'] = pd.to_datetime(df_hist['æ—¥æœŸ'])
#             df_hist.set_index('æ—¥æœŸ', inplace=True)
#
#             # 4. ç›´æ¥æœç´¢ç›®æ ‡æ—¥æœŸçš„æ”¶ç›˜ä»·å¹¶è®¡ç®—å¸‚å€¼
#             target_market_cap = {}
#             for target_date in dates:
#                 # æ‰¾åˆ°ç›®æ ‡æ—¥æœŸæˆ–ä¹‹å‰æœ€è¿‘çš„äº¤æ˜“æ—¥
#                 available_dates = df_hist.index[df_hist.index <= target_date]
#                 if len(available_dates) > 0:
#                     nearest_date = available_dates.max()
#                     if nearest_date in df_hist.index:
#                         closing_price = df_hist.loc[nearest_date, 'æ”¶ç›˜']
#                         # è®¡ç®—æ€»å¸‚å€¼å¹¶è½¬æ¢ä¸ºäº¿å…ƒ
#                         market_cap = (total_shares * closing_price) / 100000000
#                         target_market_cap[target_date] = market_cap
#                         print(f"    {target_date.date()} -> {nearest_date.date()}: {market_cap:.2f} äº¿å…ƒ")
#                     else:
#                         target_market_cap[target_date] = np.nan
#                         print(f"    {target_date.date()} -> æ— æ”¶ç›˜ä»·æ•°æ®")
#                 else:
#                     target_market_cap[target_date] = np.nan
#                     print(f"    {target_date.date()} -> æ— å†å²æ•°æ®")
#
#             all_market_caps[code] = pd.Series(target_market_cap)
#             print(f"  âˆš å·²è·å– {code} çš„å¸‚å€¼æ•°æ®")
#
#         except Exception as e:
#             print(f"  âœ— é”™è¯¯ï¼šè·å– {code} æ•°æ®å¤±è´¥ã€‚åŸå› : {e}")
#             continue
#
#     # 3. ç»“æœåˆå¹¶
#     if all_market_caps:
#         df_market_cap = pd.DataFrame(all_market_caps)
#         return df_market_cap
#     else:
#         return pd.DataFrame()
#
#
# # --- æ‰§è¡Œä»£ç  ---
# df_market_cap_result = get_market_values_for_dates(formatted_stock_codes, TARGET_DATES)
#
# # --- ç»“æœå±•ç¤º ---
# print("\n" + "=" * 50)
# print("ç»™å®šæ—¥æœŸæ€»å¸‚å€¼ç»“æœ (å•ä½: äº¿å…ƒ)")
# print("=" * 50)
# print(df_market_cap_result.round(2))  # ä¿ç•™ä¸¤ä½å°æ•°

###ç­‰æƒ
# --- ç¬¬ä¸‰æ­¥: è®¡ç®—åŠ æƒç»„åˆ ---
print("\n--- ç¬¬ä¸‰æ­¥: è®¡ç®—åŠ æƒç»„åˆ (åæ–¹å·® Ã— é£é™©æº¢ä»· Ã— ç­‰æƒé‡) ---")

# ç­‰æƒé‡è®¾ç½® (å‡è®¾æ‰€æœ‰è‚¡ç¥¨ç­‰æƒé‡)
n_stocks = len(df_sheet1.columns)
equal_weight = np.ones(n_stocks) / n_stocks
print(f"ç­‰æƒé‡å‘é‡ç»´åº¦: {equal_weight.shape}, æ¯åªè‚¡ç¥¨æƒé‡: {1 / n_stocks:.4f}")

# å­˜å‚¨æœ€ç»ˆç»“æœ
portfolio_results = {}

for date in TARGET_DATES:
    if date not in rolling_stats:
        print(f"è·³è¿‡ {date.date()} - æ— åæ–¹å·®æ•°æ®")
        continue

    if date not in target_rp_data.index:
        print(f"è·³è¿‡ {date.date()} - æ— é£é™©æº¢ä»·æ•°æ®")
        continue

    # è·å–è¯¥æ—¥æœŸçš„åæ–¹å·®çŸ©é˜µå’Œé£é™©æº¢ä»·
    cov_matrix = rolling_stats[date]['rolling_cov']
    risk_premium = target_rp_data[date]

    print(f"\nè®¡ç®—æ—¥æœŸ: {date.date()}")
    print(f"  é£é™©æº¢ä»·: {risk_premium:.6f}")
    print(f"  åæ–¹å·®çŸ©é˜µç»´åº¦: {cov_matrix.shape}")

    # æ ¸å¿ƒè®¡ç®—: åæ–¹å·® Ã— é£é™©æº¢ä»· Ã— æƒé‡
    try:
        # ç¬¬ä¸€æ­¥: åæ–¹å·®çŸ©é˜µ Ã— é£é™©æº¢ä»·
        if isinstance(cov_matrix, pd.DataFrame):
            # æ–¹æ³•1: ä½¿ç”¨ .values å¹¶ç¡®ä¿æ•°æ®ç±»å‹
            cov_matrix = cov_matrix.values.astype(np.float64)

        equal_weight = equal_weight.astype(np.float64)

        # 2. æ£€æŸ¥å¹¶å¤„ç†NaNå€¼
        nan_count = np.isnan(cov_matrix).sum()
        if nan_count > 0:
            print(f"  è­¦å‘Š: åæ–¹å·®çŸ©é˜µä¸­æœ‰ {nan_count} ä¸ªNaNå€¼ï¼Œä½¿ç”¨0å¡«å……")
            cov_matrix = np.nan_to_num(cov_matrix, nan=0.0)

        # 3. æ£€æŸ¥çŸ©é˜µå¯¹ç§°æ€§å’Œæ­£å®šæ€§
        if not np.allclose(cov_matrix, cov_matrix.T):
            print("  è­¦å‘Š: åæ–¹å·®çŸ©é˜µä¸å¯¹ç§°ï¼Œè¿›è¡Œå¯¹ç§°åŒ–å¤„ç†")
            cov_matrix = (cov_matrix + cov_matrix.T) / 2
        cov_times_rp = cov_matrix * risk_premium
        print(f"  åæ–¹å·®Ã—é£é™©æº¢ä»·çŸ©é˜µç»´åº¦: {cov_times_rp.shape}")

        # ç¬¬äºŒæ­¥: ä¹˜ä»¥ç­‰æƒé‡å‘é‡
        # è¿™é‡Œä½¿ç”¨çŸ©é˜µä¹˜æ³•: (nÃ—n) Ã— (nÃ—1) = (nÃ—1)
        portfolio_vector = cov_times_rp @ equal_weight
        # æˆ–è€…ä½¿ç”¨: portfolio_vector = np.dot(cov_times_rp, equal_weight)

        print(f"  æœ€ç»ˆç»„åˆå‘é‡ç»´åº¦: {portfolio_vector.shape}")

        # å­˜å‚¨ç»“æœ
        portfolio_results[date] = {
            'risk_premium': risk_premium,
            'cov_matrix': cov_matrix,
            'portfolio_vector': portfolio_vector,
            'calculated_on': rolling_stats[date].get('calculated_on', date)
        }

        # æ˜¾ç¤ºå‰å‡ åªè‚¡ç¥¨çš„ç»“æœé¢„è§ˆ
        print("  å‰5åªè‚¡ç¥¨çš„ç»“æœ:")
        for i, (stock_code, value) in enumerate(zip(stock_codes_raw[:5], portfolio_vector[:5])):
            print(f"    {stock_code}: {value:.8f}")

    except Exception as e:
        print(f"  è®¡ç®—å¤±è´¥: {e}")

# --- æœ€ç»ˆç»“æœæ±‡æ€» ---
print("\n" + "=" * 50)
print("æœ€ç»ˆç»“æœæ±‡æ€»")
print("=" * 50)

# --- è¾“å‡ºç»“æœåˆ°Excel (æœ€ç®€æ´ç‰ˆæœ¬) ---
if portfolio_results:
    pd.DataFrame(
        {date: data['portfolio_vector'] for date, data in portfolio_results.items()},
        index=stock_codes_raw[:len(next(iter(portfolio_results.values()))['portfolio_vector'])]
    ).to_excel("BL_æ”¶ç›Šç‡å…ˆéªŒç»“æœ.xlsx")
    print("âˆš ç»“æœå·²ä¿å­˜åˆ° BL_æ”¶ç›Šç‡å…ˆéªŒç»“æœ.xlsx")


# ===== ä»¥ä¸‹æ˜¯æ–°å¢çš„Black-Littermanæ­¥éª¤ä»£ç  =====

# --- ç¬¬ä¸€æ­¥: è¯»å…¥çŸ©é˜µPå¹¶å¤„ç† ---
def load_and_process_P(P_file_path, BL_stock_codes):
    """
    è¯»å…¥çŸ©é˜µPï¼Œå¹¶ä¸BLç»“æœçš„è‚¡ç¥¨ä»£ç å¯¹é½

    Args:
        P_file_path: PçŸ©é˜µçš„Excelæ–‡ä»¶è·¯å¾„
        BL_stock_codes: BLç»“æœä¸­çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨

    Returns:
        P_aligned: å¯¹é½åçš„PçŸ©é˜µ
    """
    # è¯»å…¥PçŸ©é˜µ
    P_raw = pd.read_excel(P_file_path, sheet_name='Sheet2',index_col=0)
    print(f"åŸå§‹PçŸ©é˜µå½¢çŠ¶: {P_raw.shape}")
    print(f"PçŸ©é˜µåŒ…å«è‚¡ç¥¨ä»£ç æ•°é‡: {len(P_raw.columns)}")

    # åˆ›å»ºä¸BLç»“æœç›¸åŒç»´åº¦çš„å…¨é›¶çŸ©é˜µ
    P_aligned = pd.DataFrame(
        np.zeros((len(P_raw), len(BL_stock_codes))),
        index=P_raw.index,  # ä¿æŒåŸæ¥çš„æ—¥æœŸç´¢å¼•
        columns=BL_stock_codes  # ä½¿ç”¨BLç»“æœçš„è‚¡ç¥¨ä»£ç 
    )

    # å°†PçŸ©é˜µä¸­å­˜åœ¨çš„è‚¡ç¥¨ä»£ç æ•°æ®å¡«å……åˆ°å¯¹é½çŸ©é˜µä¸­
    common_stocks = set(P_raw.columns) & set(BL_stock_codes)
    for stock in common_stocks:
        P_aligned[stock] = P_raw[stock]

    print(f"å¯¹é½åPçŸ©é˜µå½¢çŠ¶: {P_aligned.shape}")
    print(f"å…±å¯¹é½ {len(common_stocks)} åªè‚¡ç¥¨")
    print(P_aligned)

    return P_aligned


# --- ç¬¬äºŒæ­¥: è®¡ç®—Î©çŸ©é˜µ ---
def calculate_Omega(P, cov_matrix, tau=0.1):
    tau_Sigma = tau * cov_matrix
    P_tau_Sigma_PT = P @ tau_Sigma @ P.T
    # å–å¯¹è§’çº¿å…ƒç´ æ„æˆå¯¹è§’çŸ©é˜µ
    Omega = np.diag(np.diag(P_tau_Sigma_PT))
    print(f"Î©çŸ©é˜µå½¢çŠ¶: {Omega.shape}")
    print(f"Î©çŸ©é˜µå¯¹è§’çº¿å…ƒç´ èŒƒå›´: [{Omega.diagonal().min():.8f}, {Omega.diagonal().max():.8f}]")

    return Omega


# --- ç¬¬ä¸‰æ­¥: è®¡ç®—Qå‘é‡ ---
def calculate_Q(P, mu, Omega=None, views=None):
    """
    è®¡ç®—ä¸»è§‚æ”¶ç›Šç‡å‘é‡Q

    Args:
        P: è§‚ç‚¹çŸ©é˜µ (kÃ—n)
        mu: å…ˆéªŒæ”¶ç›Šç‡å‘é‡ (nÃ—1)
        Omega: è§‚ç‚¹ç½®ä¿¡åº¦çŸ©é˜µ (kÃ—k)ï¼Œå¯é€‰
        views: ä¸»è§‚è§‚ç‚¹å‘é‡ (kÃ—1)ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨P@mu

    Returns:
        Q: ä¸»è§‚æ”¶ç›Šç‡å‘é‡ (kÃ—1)
    """
    if views is not None:
        # å¦‚æœæœ‰æ˜ç¡®çš„ä¸»è§‚è§‚ç‚¹å€¼
        Q = np.array(views).reshape(-1, 1)
    else:
        # Q = PÎ¼ + Îµ_qï¼Œè¿™é‡ŒÎµ_qå‡å€¼ä¸º0ï¼Œåœ¨åç»­è®¡ç®—ä¸­è€ƒè™‘
        Q = P @ mu + np.random.multivariate_normal(np.zeros(Omega.shape[0]), Omega).reshape(-1, 1)

    print(f"Qå‘é‡å½¢çŠ¶: {Q.shape}")
    print(f"Qå‘é‡èŒƒå›´: [{Q.min():.8f}, {Q.max():.8f}]")

    return Q


# --- ä¸»æ‰§è¡Œå‡½æ•° ---
def execute_BL_steps(P_file_path, BL_results, tau=0.05, views=None):
    """
    æ‰§è¡ŒBlack-Littermançš„ä¸‰ä¸ªæ­¥éª¤

    Args:
        P_file_path: PçŸ©é˜µæ–‡ä»¶è·¯å¾„
        BL_results: ä¹‹å‰è®¡ç®—çš„BLç»“æœå­—å…¸
        tau: ä¿¡å¿ƒç¨‹åº¦å‚æ•°
        views: ä¸»è§‚è§‚ç‚¹å‘é‡åˆ—è¡¨

    Returns:
        results: åŒ…å«P, Omega, Qçš„ç»“æœå­—å…¸
    """
    results = {}

    # è·å–BLç»“æœä¸­çš„è‚¡ç¥¨ä»£ç ï¼ˆä»ç¬¬ä¸€ä¸ªæ—¥æœŸçš„portfolio_vectoré•¿åº¦è·å–ï¼‰
    if not BL_results:
        print("é”™è¯¯: æ— æœ‰æ•ˆçš„BLç»“æœ")
        return results

    # è·å–è‚¡ç¥¨ä»£ç ï¼ˆä½¿ç”¨ä¹‹å‰è®¡ç®—ä¸­ä½¿ç”¨çš„è‚¡ç¥¨ä»£ç ï¼‰
    first_date = list(BL_results.keys())[0]
    BL_stock_codes = stock_codes_raw[:len(BL_results[first_date]['portfolio_vector'])]

    # ç¬¬ä¸€æ­¥: å¤„ç†PçŸ©é˜µ
    print("=== ç¬¬ä¸€æ­¥: è¯»å…¥å¹¶å¤„ç†PçŸ©é˜µ ===")
    P_aligned = load_and_process_P(P_file_path, BL_stock_codes)
    results['P'] = P_aligned

    # å¯¹æ¯ä¸ªæ—¥æœŸåˆ†åˆ«è®¡ç®—
    for date, bl_data in BL_results.items():
        print(f"\n=== å¤„ç†æ—¥æœŸ: {date} ===")

        # è·å–è¯¥æ—¥æœŸçš„åæ–¹å·®çŸ©é˜µå’Œç»„åˆå‘é‡
        cov_matrix = bl_data['cov_matrix']
        portfolio_vector = bl_data['portfolio_vector']####å…ˆéªŒå‡å€¼

        # ç¬¬äºŒæ­¥: è®¡ç®—Î©
        print("=== ç¬¬äºŒæ­¥: è®¡ç®—Î©çŸ©é˜µ ===")
        Omega = calculate_Omega(P_aligned.values, cov_matrix, tau)

        # ç¬¬ä¸‰æ­¥: è®¡ç®—Q
        print("=== ç¬¬ä¸‰æ­¥: è®¡ç®—Qå‘é‡ ===")
        # ä½¿ç”¨ç»„åˆå‘é‡ä½œä¸ºå…ˆéªŒæ”¶ç›Šç‡ä¼°è®¡
        Q = calculate_Q(P_aligned.values, portfolio_vector.reshape(-1, 1), Omega, views)

        # å­˜å‚¨ç»“æœ
        results[date] = {
            'P': P_aligned,
            'Omega': Omega,
            'Q': Q,
            'cov_matrix': cov_matrix,
            'portfolio_vector': portfolio_vector
        }

    return results


# --- æ‰§è¡ŒBlack-Littermanæ­¥éª¤ ---
print("\n" + "=" * 60)
print("å¼€å§‹æ‰§è¡ŒBlack-Littermanæ¨¡å‹æ­¥éª¤")
print("=" * 60)

# è®¾ç½®PçŸ©é˜µæ–‡ä»¶è·¯å¾„ï¼ˆéœ€è¦ä½ æä¾›å®é™…è·¯å¾„ï¼‰
P_FILE_PATH = r"C:\Users\cufet\Desktop\è½¬æ¢åæ•°æ®.xlsx"  # è¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„

try:
    # æ‰§è¡Œä¸‰ä¸ªæ­¥éª¤
    BL_steps_results = execute_BL_steps(
        P_file_path=P_FILE_PATH,
        BL_results=portfolio_results,  # ä½¿ç”¨ä¹‹å‰è®¡ç®—çš„BLç»“æœ
        tau=0.1,
        views=None  # å¯ä»¥ä¼ å…¥å…·ä½“è§‚ç‚¹æˆ–ä½¿ç”¨Noneè‡ªåŠ¨è®¡ç®—
    )

    # ä¿å­˜ç»“æœ
    if BL_steps_results:
        # åˆ›å»ºExcelå†™å…¥å™¨
        with pd.ExcelWriter("BL_å®Œæ•´ç»“æœ.xlsx") as writer:
            # ä¿å­˜å…ˆéªŒç»“æœ
            pd.DataFrame(
                {date: data['portfolio_vector'] for date, data in portfolio_results.items()},
                index=stock_codes_raw[:len(next(iter(portfolio_results.values()))['portfolio_vector'])]
            ).to_excel(writer, sheet_name='å…ˆéªŒæ”¶ç›Šç‡')

            # ä¿å­˜PçŸ©é˜µ
            BL_steps_results['P'].to_excel(writer, sheet_name='PçŸ©é˜µ')

            # ä¿å­˜æ¯ä¸ªæ—¥æœŸçš„Î©å’ŒQ
            for date, data in BL_steps_results.items():
                if date != 'P':  # è·³è¿‡PçŸ©é˜µæœ¬èº«
                    # pd.DataFrame(data['Omega']).to_excel(writer, sheet_name=f'{date.date()}_Omega')
                    # pd.DataFrame(data['Q']).to_excel(writer, sheet_name=f'{date.date()}_Q')
                    pd.DataFrame(data['Omega'], index=BL_steps_results['P'].index).to_excel(writer,
                                                                                            sheet_name=f'{date.date()}_Omega')
                    pd.DataFrame(data['Q'], index=stock_codes_raw[:len(data['Q'])], columns=['Q_value']).to_excel(writer, sheet_name=f'{date.date()}_Q')

        print("\nâˆš æ‰€æœ‰Black-Littermanç»“æœå·²ä¿å­˜åˆ° BL_å®Œæ•´ç»“æœ.xlsx")
        print("  åŒ…å«: å…ˆéªŒæ”¶ç›Šç‡, PçŸ©é˜µ, å„æ—¥æœŸÎ©çŸ©é˜µ, å„æ—¥æœŸQå‘é‡")

except FileNotFoundError:
    print(f"âœ— æ‰¾ä¸åˆ°PçŸ©é˜µæ–‡ä»¶: {P_FILE_PATH}")
    print("è¯·ç¡®ä¿PçŸ©é˜µæ–‡ä»¶è·¯å¾„æ­£ç¡®")
except Exception as e:
    print(f"âœ— Black-Littermanæ­¥éª¤æ‰§è¡Œå¤±è´¥: {e}")

print("\n" + "=" * 60)
print("ç¨‹åºæ‰§è¡Œå®Œæˆ")
print("=" * 60)

# --- æå–æŒ‡å®šæ—¥æœŸçš„éé›¶å…ƒç´  ---
print("\n" + "=" * 60)
print("æå–æŒ‡å®šæ—¥æœŸçš„éé›¶å…ƒç´ ")
print("=" * 60)

try:
    nonzero_results = []

    # åªå¤„ç†TARGET_DATESä¸­çš„æ—¥æœŸ
    for target_date in TARGET_DATES:
        if target_date in BL_steps_results and target_date in portfolio_results:
            data = BL_steps_results[target_date]
            portfolio_data = portfolio_results[target_date]
            print(f"\nå¤„ç†æŒ‡å®šæ—¥æœŸ: {target_date.date()}")
            # è·å–è¯¥æ—¥æœŸçš„cov_matrixã€PçŸ©é˜µã€Qå‘é‡ã€Î©çŸ©é˜µ
            cov_matrix = portfolio_data['cov_matrix']
            P_matrix = data['P']
            Q_vector = data['Q']
            Omega_matrix = data['Omega']
            portfolio_vector_before = data['portfolio_vector']


            # è·å–è¯¥æ—¥æœŸçš„sigma(cov_matrix)ã€PçŸ©é˜µã€Qå‘é‡ã€Î©çŸ©é˜µ
            P_df = BL_steps_results['P']
            # P_matrix_one = data['P'].loc[target_date]
            nearest_date = data['P'].index[data['P'].index >= target_date][0]
            P_matrix_one = data['P'].loc[[nearest_date]]
            date_index = data['P'].index.get_loc(nearest_date)####è¿™æ˜¯å› ä¸ºPå’ŒQçš„ç»“æ„ç›¸åŒ
            Q_vector_one = data['Q'][date_index]  # ç›´æ¥ä½¿ç”¨ç´¢å¼•ä½ç½®
            # ä½¿ç”¨å‘åæŸ¥æ‰¾æ–¹æ³•
            indexer = P_df.index.get_indexer([target_date], method='backfill')[0]
            if indexer != -1:
                date_index = indexer
                actual_date = P_df.index[date_index]
                print(f"ç›®æ ‡æ—¥æœŸ: {target_date.date()}, å®é™…ä½¿ç”¨çš„æ—¥æœŸ: {actual_date.date()}, ä½ç½®: {date_index}")

                if actual_date != target_date:
                    print(f"æ³¨æ„: ä½¿ç”¨è¿‘ä¼¼æ—¥æœŸ {actual_date.date()} ä»£æ›¿ç›®æ ‡æ—¥æœŸ {target_date.date()}")
            else:
                print(f"è­¦å‘Š: æ— æ³•ä¸ºæ—¥æœŸ {target_date.date()} æ‰¾åˆ°ä»»ä½•åŒ¹é…çš„æ—¥æœŸ")
                continue

            if date_index < Omega_matrix.shape[0]:
                omega_value = Omega_matrix[date_index, date_index]
                print(f"è·å–Î©çŸ©é˜µå¯¹è§’çº¿ä¸Šçš„ç¬¬{date_index}ä¸ªå…ƒç´ : {omega_value}")



            # å¦‚æœè¯¥å…ƒç´ ä¸ä¸ºé›¶ï¼Œåˆ™è®°å½•ç»“æœ
                if omega_value != 0:
                    result_entry = {
                        'date': target_date,
                        'cov_matrix': cov_matrix,  # ä½¿ç”¨cov_matrix
                        'omega_value': omega_value,
                        'P_matrix': P_matrix,
                        'P_matrix_one': P_matrix_one,
                        'Q_vector': Q_vector,
                        'Q_vector_one':Q_vector_one,
                        'portfolio_vector_before': portfolio_vector_before,
                        'date_index': date_index  # è®°å½•æ—¥æœŸåœ¨åˆ—è¡¨ä¸­çš„ç´¢å¼•ä½ç½®
                    }
                    nonzero_results.append(result_entry)
            else:
                print(f"è­¦å‘Š: æ—¥æœŸç´¢å¼•{date_index}è¶…å‡ºÎ©çŸ©é˜µç»´åº¦{Omega_matrix.shape}")

except Exception as e:
    print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

def calculate_bl_posterior(result_entry, tau=0.1):
    """
    æ ¹æ®Black-Littermanå…¬å¼è®¡ç®—åéªŒåˆ†å¸ƒ
    """
    try:
        # æå–æ•°æ®
        Sigma = np.array(result_entry['cov_matrix'])  # Î£
        P = np.array(result_entry['P_matrix_one'])  # P
        Q = np.array(result_entry['Q_vector_one'])  # Q
        Pi = np.array(result_entry['portfolio_vector_before'])  # Î  (å…ˆéªŒæ”¶ç›Š)
        omega_value = result_entry['omega_value']  # Î©çš„å¯¹è§’çº¿å€¼
        Pi = Pi.reshape(-1, 1)
        Q = Q.reshape(-1, 1)
        print(f"çŸ©é˜µç»´åº¦ - Î£: {Sigma.shape}, P: {P.shape}, Q: {Q.shape}, Î : {Pi.shape}")
        regularization = 1e-6 * np.eye(Sigma.shape[0])
        Sigma = Sigma + regularization

        # 2. æ£€æŸ¥å¹¶å¤„ç†Î©çŸ©é˜µ
        if omega_value <= 0:
            omega_value = 1e-4  # è®¾ç½®æœ€å°æ­£å€¼
            print(f"è°ƒæ•´omega_valueä¸º: {omega_value}")
        n_views = P.shape[0]
        Omega = np.eye(n_views) * omega_value
        # Q = np.eye(n_views) * Q


        # è®¡ç®—é€†çŸ©é˜µ
        Sigma_inv = np.linalg.inv(Sigma)
        Omega_inv = np.linalg.inv(Omega)

        # è®¡ç®—åéªŒåæ–¹å·®çŸ©é˜µ Î£_p
        term1 = tau * Sigma_inv
        term2 = P.T @ Omega_inv @ P
        posterior_cov = np.linalg.inv(term1 + term2)

        # è®¡ç®—åéªŒé¢„æœŸæ”¶ç›Š Î¼Ìƒ
        term3 = tau * Sigma_inv @ Pi
        term4 = P.T @ Omega_inv @ Q
        posterior_mean = posterior_cov @ (term3 + term4)

        print("åéªŒè®¡ç®—æˆåŠŸ")
        return posterior_mean, posterior_cov

    except Exception as e:
        print(f"åéªŒè®¡ç®—å¤±è´¥: {e}")
        return None, None


# è®¡ç®—æ‰€æœ‰ç»“æœçš„åéªŒåˆ†å¸ƒ
try:
    posterior_results = []

    for i, result in enumerate(nonzero_results):
        print(f"\n=== è®¡ç®—ç¬¬ {i + 1} ä¸ªæ—¥æœŸçš„åéªŒåˆ†å¸ƒ: {result['date'].date()} ===")

        posterior_mean, posterior_cov = calculate_bl_posterior(result)

        if posterior_mean is not None:
            # æ·»åŠ åˆ°ç»“æœä¸­
            result.update({
                'posterior_mean': posterior_mean,
                'posterior_cov': posterior_cov
            })
            posterior_results.append(result)
            print(f"âœ“ æ—¥æœŸ {result['date'].date()} çš„åéªŒè®¡ç®—å®Œæˆ")

    print(f"\n=== åéªŒè®¡ç®—æ±‡æ€» ===")
    print(f"æˆåŠŸè®¡ç®—: {len(posterior_results)} ä¸ªæ—¥æœŸ")

except Exception as e:
    print(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

# --- å¿…é¡»ç¡®ä¿åœ¨æ–‡ä»¶å¼€å¤´å¯¼å…¥äº† pandas å’Œ numpy ---
# # è¾“å‡ºåˆ°Excel (ç®€åŒ–ç‰ˆ)
# --- å¿…é¡»ç¡®ä¿åœ¨æ–‡ä»¶å¼€å¤´å¯¼å…¥äº† pandas å’Œ numpy ---
# # è¾“å‡ºåˆ°Excel (ç®€åŒ–ç‰ˆ)
def save_posterior_to_excel_simple(posterior_results, filename='bl_posterior_results_simple.xlsx'):
    if not posterior_results:
        print("æ²¡æœ‰å¯ä¿å­˜çš„åéªŒç»“æœã€‚")
        return False
    global stock_codes_raw

    try:
        # å¼ºåˆ¶ä½¿ç”¨ xlsxwriter å¼•æ“ (å·²æ ¹æ®ä½ ä¹‹å‰çš„ä¿®æ”¹ä¿ç•™)
        with pd.ExcelWriter(filename, engine='xlsxwriter') as writer:
            for result in posterior_results:
                date_str = result['date'].strftime('%Y-%m-%d')

                # æ‰å¹³åŒ–æ•°æ®ä»¥ç¡®ä¿æ­£ç¡®åˆ›å»º DataFrame
                prior_returns = np.array(result['portfolio_vector_before']).flatten()
                posterior_returns = np.array(result['posterior_mean']).flatten()
                N = len(posterior_returns)  # ä½¿ç”¨æ‰å¹³åŒ–åçš„é•¿åº¦

                # è·å–å¯¹åº”äºå½“å‰èµ„äº§æ•°é‡ N çš„è‚¡ç¥¨åç§°åˆ—è¡¨
                # å‡è®¾ stock_codes_raw åŒ…å«äº†æ‰€æœ‰è‚¡ç¥¨åç§°ï¼Œä¸”é¡ºåºå¯¹åº”äºè®¡ç®—ç»“æœ
                asset_names = stock_codes_raw[:N]

                # å…ˆéªŒvsåéªŒæ”¶ç›Šæ¯”è¾ƒ
                comparison_df = pd.DataFrame({
                    # ***ä¿®æ”¹ç‚¹ï¼šå°† 'Asset_Index' æ›¿æ¢ä¸º 'Asset_Code' å¹¶ä½¿ç”¨è‚¡ç¥¨åç§°åˆ—è¡¨***
                    'Asset_Code': asset_names,
                    'Prior_Returns': prior_returns,
                    'Posterior_Returns': posterior_returns,
                    'Difference': posterior_returns - prior_returns
                })

                # ***ä¿®æ”¹ç‚¹ï¼šå¦‚æœä½ æƒ³è®©è‚¡ç¥¨ä»£ç ä½œä¸ºç´¢å¼•ï¼Œå¯ä»¥è¿™æ ·åšï¼š***
                # comparison_df = pd.DataFrame({
                #     'Prior_Returns': prior_returns,
                #     'Posterior_Returns': posterior_returns,
                #     'Difference': posterior_returns - prior_returns
                # }, index=asset_names)
                # comparison_df.to_excel(writer, sheet_name=f'{date_str}_Returns', index=True) # index=True

                comparison_df.to_excel(writer, sheet_name=f'{date_str}_Returns', index=False)

                # åéªŒåæ–¹å·®çŸ©é˜µ
                posterior_cov = np.array(result['posterior_cov'])
                if posterior_cov.dtype == object:
                    posterior_cov = np.array([[float(x) for x in row] for row in posterior_cov])

                posterior_cov_df = pd.DataFrame(posterior_cov)
                # æ›´å¥½çš„åšæ³•æ˜¯ç»™åæ–¹å·®çŸ©é˜µåŠ ä¸Šè‚¡ç¥¨ä»£ç ä½œä¸ºè¡Œç´¢å¼•å’Œåˆ—å
                posterior_cov_df.index = asset_names
                posterior_cov_df.columns = asset_names
                posterior_cov_df.to_excel(writer, sheet_name=f'{date_str}_posterior_Covariance', index=True)  # åæ–¹å·®çŸ©é˜µé€šå¸¸ä¿ç•™ç´¢å¼•

                # PçŸ©é˜µå’ŒQå‘é‡ (å·²ä¿®å¤ Q å‘é‡æœªå®šä¹‰å˜é‡çš„é—®é¢˜)
                P_df = pd.DataFrame(result['P_matrix_one'])

                # ç¡®ä¿ Q å‘é‡æ˜¯ä¸€ç»´æ•°ç»„å¹¶åŠ ä¸Šåˆ—å
                Q_vector_data = np.array(result['Q_vector_one']).flatten()
                Q_df = pd.DataFrame({'Q_Vector': Q_vector_data})

                P_df.to_excel(writer, sheet_name=f'{date_str}_P_Matrix', index=False)
                Q_df.to_excel(writer, sheet_name=f'{date_str}_Q_Vector', index=False)

            # 3. æ‰€æœ‰åéªŒ/å…ˆéªŒæ”¶ç›Šçš„åˆå¹¶è§†å›¾
            all_posterior_data = {}
            all_prior_data = {}

            for result in posterior_results:
                date_str = result['date'].strftime('%Y-%m-%d')
                # åœ¨è¿™é‡Œä¹Ÿç¡®ä¿æ•°æ®æ˜¯æ‰å¹³çš„
                all_posterior_data[date_str] = np.array(result['posterior_mean']).flatten()
                all_prior_data[date_str] = np.array(result['portfolio_vector_before']).flatten()

            # ç¡®ä¿æ‰€æœ‰å‘é‡é•¿åº¦ä¸€è‡´
            max_length = max(len(mean) for mean in all_posterior_data.values())

            for data_dict in [all_posterior_data, all_prior_data]:
                for date_str, mean_vector in data_dict.items():
                    if len(mean_vector) < max_length:
                        data_dict[date_str] = np.pad(mean_vector,
                                                     (0, max_length - len(mean_vector)),
                                                     constant_values=np.nan)

            # ç¡®å®šåˆå¹¶è§†å›¾çš„ç´¢å¼• (ä½¿ç”¨æœ€å¤§é•¿åº¦å¯¹åº”çš„è‚¡ç¥¨ä»£ç )
            max_asset_names = stock_codes_raw[:max_length]

            all_posterior_df = pd.DataFrame(all_posterior_data)
            all_prior_df = pd.DataFrame(all_prior_data)

            # ***ä¿®æ”¹ç‚¹ï¼šè®¾ç½®åˆå¹¶è§†å›¾çš„ç´¢å¼•***
            all_posterior_df.index = max_asset_names
            all_prior_df.index = max_asset_names

            all_posterior_df.to_excel(writer, sheet_name='All_Posterior_Returns', index=True)  # index=True
            all_prior_df.to_excel(writer, sheet_name='All_Prior_Returns', index=True)  # index=True

        print(f"åéªŒç»“æœå·²ä¿å­˜åˆ°: {filename}")
        return True

    except Exception as e:
        print(f"ä¿å­˜Excelæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False


# æ‰§è¡Œä¿å­˜
if posterior_results:
    success = save_posterior_to_excel_simple(posterior_results)
    if success:
        print("ğŸ‰ Excelæ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
else:
    print("æ²¡æœ‰å¯ä¿å­˜çš„åéªŒç»“æœ")
